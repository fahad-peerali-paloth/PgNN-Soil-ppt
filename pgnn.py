# -*- coding: utf-8 -*-
"""PgNN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Qu1QB08Bx1wtkYgmOSDnS-sMvA17ZUCi
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from keras.models import Sequential
from keras.layers import LSTM, Dense
import tensorflow as tf
from keras import backend as K

excel_file_path = 'combined_processed_output.xlsx'
sheet_name = 'Sheet1'
df = pd.read_excel(excel_file_path, sheet_name)

X = df.iloc[:, 0:4].values
Y = df.iloc[:, 4:10].values

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)


scaler_X = MinMaxScaler()
scaler_Y = MinMaxScaler()
X_train_scaled = scaler_X.fit_transform(X_train)
X_test_scaled = scaler_X.transform(X_test)
Y_train_scaled = scaler_Y.fit_transform(Y_train)
Y_test_scaled = scaler_Y.transform(Y_test)


time_steps = 1
X_train_lstm = np.reshape(X_train_scaled, (X_train_scaled.shape[0], time_steps, X_train_scaled.shape[1]))
X_test_lstm = np.reshape(X_test_scaled, (X_test_scaled.shape[0], time_steps, X_test_scaled.shape[1]))

Y_train_scaled

from tensorflow.python.ops.array_ops import zeros
import tensorflow as tf
from keras import backend as K


def custom_loss_combined(y_true, y_pred):
    num_components = K.int_shape(y_true)[-1]
    n_true=y_true[:,0]
    k_true=y_true[:,1]
    c_true=y_true[:,2]
    phi_true=y_true[:,3]
    k_c_true=y_true[:,4]
    k_phi_true=y_true[:,5]

    n_pred=y_pred[:,0]
    k_pred=y_pred[:,1]
    c_pred=y_pred[:,2]
    phi_pred=y_pred[:,3]
    k_c_pred=y_pred[:,4]
    k_phi_pred=y_pred[:,5]

    normal_stress_true=-1*n_true*(-1*k_phi_true*phi_true-1*k_c_true*c_true)
    normal_stress_pred=-1*n_pred*(-1*k_phi_pred*phi_pred-1*k_c_pred*c_pred)


    L1_loss = K.mean(K.square(y_true - y_pred))
    L2_loss = K.mean(K.square(normal_stress_true - normal_stress_pred))

    L_combined = L1_loss + L2_loss

    return L_combined

model = Sequential()
model.add(LSTM(units=50, activation='relu', input_shape=(X_train_lstm.shape[1], X_train_lstm.shape[2])))
model.add(Dense(Y_train_scaled.shape[1]))


model.compile(optimizer='adam', loss=custom_loss_combined)

batch_size = 8
history = model.fit(X_train_lstm, Y_train_scaled, epochs=100, batch_size=batch_size, validation_data=(X_test_lstm, Y_test_scaled))

import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import mean_squared_error
from math import sqrt
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from keras.models import Sequential
from keras.layers import LSTM, Dense


y_pred_scaled = model.predict(X_test_lstm)
y_pred = scaler_Y.inverse_transform(y_pred_scaled)
Y_test = scaler_Y.inverse_transform(Y_test_scaled)
rmse = sqrt(mean_squared_error(Y_test, y_pred))

print(f"RMSE: {rmse:.2f}")


plt.figure(figsize=(12, 6))


plt.subplot(1, 2, 1)
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend(['Train', 'Validation'], loc='upper left')

plt.tight_layout()
plt.show()

for i in range(6):
    plt.figure(figsize=(10, 6))
    plt.plot(Y_test[1:100, i], label='Actual Data', color='blue')
    plt.plot(y_pred[1:100, i], label='Predicted Data', color='red')
    plt.xlabel('Time Step')
    plt.ylabel('Value')
    plt.title(f'Actual vs. Predicted Data (Variable {i})')
    plt.legend()
    plt.show()

import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import mean_squared_error
from math import sqrt
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from keras.models import Sequential
from keras.layers import LSTM, Dense
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from keras.models import Sequential
from keras.layers import LSTM, Dense
from keras.models import Model
from keras.layers import Input, Conv1D, LSTM, Dense, Flatten, GRU


X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)


scaler_X = MinMaxScaler()
scaler_Y = MinMaxScaler()
X_train_scaled = scaler_X.fit_transform(X_train)
X_test_scaled = scaler_X.transform(X_test)
Y_train_scaled = scaler_Y.fit_transform(Y_train)
Y_test_scaled = scaler_Y.transform(Y_test)


time_steps = 1
X_train_lstm = np.reshape(X_train_scaled, (X_train_scaled.shape[0], time_steps, X_train_scaled.shape[1]))
X_test_lstm = np.reshape(X_test_scaled, (X_test_scaled.shape[0], time_steps, X_test_scaled.shape[1]))


input_layer = Input(shape=(X_train_lstm.shape[1], X_train_lstm.shape[2]))


conv_layer = Conv1D(filters=64, kernel_size=1, activation='relu')(input_layer)


lstm_layer1 = LSTM(units=128, activation='relu', return_sequences=True)(conv_layer)
lstm_layer2 = LSTM(units=128, activation='relu', return_sequences=True)(lstm_layer1)
lstm_layer3 = LSTM(units=64, activation='relu')(lstm_layer2)


output_layer = Dense(Y_train_scaled.shape[1])(lstm_layer3)


model = Model(inputs=input_layer, outputs=output_layer)

model.compile(optimizer='adam', loss=custom_loss_combined)
model.summary()

import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import mean_squared_error
from math import sqrt
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from keras.models import Sequential
from keras.layers import LSTM, Dense
batch_size = 8
history = model.fit(X_train_lstm, Y_train_scaled, epochs=100, batch_size=batch_size, validation_data=(X_test_lstm, Y_test_scaled))


y_pred_scaled = model.predict(X_test_lstm)
y_pred = scaler_Y.inverse_transform(y_pred_scaled)
Y_test = scaler_Y.inverse_transform(Y_test_scaled)
rmse = sqrt(mean_squared_error(Y_test, y_pred))

print(f"RMSE: {rmse:.2f}")

# Create plots for training and validation loss
plt.figure(figsize=(12, 6))

# Plot training & validation loss values
plt.subplot(1, 2, 1)
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend(['Train', 'Validation'], loc='upper left')

plt.tight_layout()
plt.show()

for i in range(6):
    plt.figure(figsize=(10, 6))
    plt.plot(Y_test[1:100, i], label='Actual Data', color='blue')
    plt.plot(y_pred[1:100, i], label='Predicted Data', color='red')
    plt.xlabel('Time Step')
    plt.ylabel('Value')
    plt.title(f'Actual vs. Predicted Data (Variable {i})')
    plt.legend()
    plt.show()